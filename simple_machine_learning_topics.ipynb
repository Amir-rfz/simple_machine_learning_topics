{"cells":[{"cell_type":"markdown","metadata":{"id":"v_MXsVuIVPSJ"},"source":["## Autoencoder in Machine Learning\n","\n","An autoencoder is a type of artificial neural network used to learn efficient data representations in an unsupervised manner. It consists of two parts:\n","\n","1. **Encoder**: Compresses the input data into a lower-dimensional representation.\n","2. **Decoder**: Reconstructs the original data from this compressed representation.\n","\n","Autoencoders are commonly used for tasks like dimensionality reduction, image denoising, and anomaly detection. The goal is to minimize the difference between the input and the reconstructed output.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6806,"status":"ok","timestamp":1729115834917,"user":{"displayName":"Amir Arefzadeh","userId":"16003684502042665289"},"user_tz":-210},"id":"9napo64yVR92","outputId":"cc4c85cd-2c1d-48c9-ce9b-084d4af8f41d"},"outputs":[{"ename":"","evalue":"","output_type":"error","traceback":["\u001b[1;31mRunning cells with 'Python 3.11.7' requires the ipykernel package.\n","\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n","\u001b[1;31mCommand: 'c:/msys64/ucrt64/bin/python3.11.exe -m pip install ipykernel -U --user --force-reinstall'"]}],"source":["from keras.datasets import mnist\n","(_, _), (test_images, _) = mnist.load_data()\n","test_images = test_images.reshape(test_images.shape[0], -1)\n","test_images = test_images.astype('float32') / 255.0"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":425},"executionInfo":{"elapsed":967,"status":"error","timestamp":1729115838523,"user":{"displayName":"Amir Arefzadeh","userId":"16003684502042665289"},"user_tz":-210},"id":"ntHpEyq_VVhU","outputId":"32f9869a-82a5-4e7f-e4fb-d16b666ee9d8"},"outputs":[],"source":["import tensorflow as tf\n","autoencoder = tf.keras.models.load_model('mnist_AE.h5')\n","reconstructed_images = autoencoder.predict(test_images)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WlRiJ6MXVhFa"},"outputs":[],"source":["import numpy as np\n","from matplotlib.pyplot import imshow\n","import matplotlib.pyplot as plt\n","\n","test1=np.array(test_images[4])\n","test1 = test1.reshape((28,28))\n","\n","imshow(test1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ft_yQq8sVkmG"},"outputs":[],"source":["test1ec=np.array(reconstructed_images[4])\n","test1ec = test1ec.reshape((28,28))\n","imshow(test1ec)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zNseHwllVoPJ"},"outputs":[],"source":["def MSE(pixels,pixelsec):\n","    pixels=np.array(pixels)\n","    pixelsec=np.array(pixelsec)\n","    sum=0\n","    for i in range(pixels.size):\n","        sum=sum+((1/pixels.size)*(pixels[i]-pixelsec[i])**2)\n","    return sum\n","\n","mse=np.array([])\n","for i in range(10000):\n","    mse=np.append(mse,MSE(test_images[i],reconstructed_images[i]))\n","\n","mse"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KFtfNq-aVq_q"},"outputs":[],"source":["plt.hist(mse,bins=50,edgecolor='black')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Q-8jYJ7uVtwy"},"outputs":[],"source":["from scipy import stats\n","ks_statistic, p_value = stats.kstest(mse, cdf='norm', args=(np.average(mse), np.std(mse)))\n","print(p_value)"]},{"cell_type":"markdown","metadata":{"id":"M8GJGIDrVutO"},"source":["## Regression and Least Squares\n","\n","**Regression** is a statistical method used to model the relationship between a dependent variable and one or more independent variables. It helps in predicting the value of the dependent variable based on the values of the independent variables.\n","\n","One of the most common techniques for fitting a regression model is **Least Squares**. This method minimizes the sum of the squared differences between the observed values and the predicted values from the model. The goal is to find the best-fitting line (or curve) that reduces these differences as much as possible.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rLa0Ue3LWAc0"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","import numpy as np\n","x_value = [-2.3, -1.1, 0.5, 3.2, 4.0, 6.7, 10.3, 11.5, 20.4]\n","y_value = [ -9.6, -4.9, -4.1, 2.7, 5.9, 10.8, 18.9, 20.5, 31.3]\n","plt.scatter(x_value, y_value, color='blue')\n","plt.xlabel('x_value')\n","plt.ylabel('y_value')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"p2Y-z53cWIDi"},"outputs":[],"source":["x = x_value\n","y = y_value\n","def avg(data):\n","     my_temp = 0\n","     for i in range (0, len(x_value)):\n","          my_temp = my_temp + data[i]\n","     return(my_temp/len(x_value))\n","\n","avg_x = avg(x)\n","avg_y = avg(y)\n","\n","def areg():\n","     a_sorat = 0\n","     a_makhraj = 0\n","     for i in range (0, len(x_value)):\n","          a_sorat = a_sorat + ((x[i] - avg_x)*(y[i] - avg_y))\n","          a_makhraj = a_makhraj + ((x[i] - avg_x)**2)\n","     return(a_sorat/a_makhraj)\n","\n","a = areg()\n","b = avg_y - (a * avg_x)\n","\n","def regression(x):\n","     return(b + (a * x))\n","\n","\n","y_regression = []\n","for i in range(0, len(x_value)):\n","      y_regression.append(regression(x_value[i]))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"es1ZFT8HWLI4"},"outputs":[],"source":["plt.scatter(x_value, y_value, color='blue')\n","plt.scatter(x_value, y_regression, color='red')\n","plt.xlabel('x_value')\n","plt.ylabel('y_value')\n","plt.plot(x_value, y_regression, color='orange')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"c4wMmYoLWPr-"},"outputs":[],"source":["rss = 0\n","for i in range(0, len(x_value)):\n","    rss=rss+(y_value[i]-regression(x_value[i]))**2\n","\n","tss=0\n","for i in range(0, len(x_value)):\n","    tss=tss+(y_value[i]-np.average(y_value))**2\n","\n","print(f\"the R2 value is: {1-(rss/tss)}\")"]},{"cell_type":"markdown","metadata":{"id":"qNUOxxLHWe9i"},"source":["## Central Limit Theorem and Sampling\n","\n","The **Central Limit Theorem (CLT)** states that the distribution of the sample mean approaches a normal distribution as the sample size increases, regardless of the original population distribution, provided the samples are independent and identically distributed.\n","\n","In practice, **sampling** involves selecting a subset of data from a larger population to make inferences about the entire population. The CLT ensures that, with a sufficiently large sample size, the sampling distribution of the mean will be approximately normal, which allows for easier statistical analysis and hypothesis testing.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"G2Flf1UKWhRX"},"outputs":[],"source":["import pandas as pd\n","import numpy\n","df = pd.read_csv('FIFA2020.csv', encoding = \"ISO-8859-1\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rb2igU-2Wl8c"},"outputs":[],"source":["for i in range(len(df)):\n","    if numpy.isnan(df['pace'][i]):\n","        df['pace'][i]=numpy.average(df.loc[i, ['pace_acceleration', 'pace_sprint_speed']])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ovjh4amlWqEx"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","import numpy as np\n","\n","# Creating dataset\n","np.random.seed(10)\n","\n","data = np.random.choice(df['age'], 100, replace=False)\n","\n","print(f\"Max is: {np.max(data)}\")\n","print(f\"Min is: {np.min(data)}\")\n","print(f\"Q1 is: {np.percentile(data,25)}\")\n","print(f\"Q2 is: {np.percentile(data,50)}\")\n","print(f\"Q3 is: {np.percentile(data,75)}\")\n","# Creating plot\n","plt.boxplot(data, autorange=True)\n","# show plot\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qQNN-nfJWzf7"},"outputs":[],"source":["data = np.random.choice(df['weight'], 100, replace=False)\n","print(f\"Average is: {np.average(data)}\")\n","print(f\"Variance is: {np.var(data)}\")\n","print(f\"Standard Variation is: {np.std(data)}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5NgtkfzjW1op"},"outputs":[],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","\n","\n","def Q_Q_two_sample(x, y):\n","# Quantile-quantile plot\n","    plt.figure()\n","    plt.scatter(np.sort(x), np.sort(y))\n","    plt.xlabel('X')\n","    plt.ylabel('Y')\n","    plt.show()\n","    plt.close()\n","\n","\n","\n","norm = np.random.normal(np.average(data), np.std(data), len(data))\n","\n","Q_Q_two_sample(norm, data)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qU5Xt_akW4KC"},"outputs":[],"source":["import scipy.stats as stats\n","statistic, p_value = stats.shapiro(data)\n","print(p_value)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rgj-OFOwW7AU"},"outputs":[],"source":["po_data = np.random.poisson(3, 5000)\n","\n","plt.hist(po_data,bins=10,edgecolor='black')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jDoZxjosW9fK"},"outputs":[],"source":["n = 50\n","po_data = np.random.poisson(3, n)\n","norm = np.random.normal(np.mean(po_data), np.std(po_data), n)\n","Q_Q_two_sample(norm, po_data)\n","_, p_value = stats.shapiro(po_data)\n","print(p_value)"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyMq4U/VowJFeMDyPf9sV4px","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.2"}},"nbformat":4,"nbformat_minor":0}
